{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc0fcf-893f-46e3-baf8-da49db5ccd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project to distinguish stages in diabetic retinopathy from mild, moderate, no_dr, proliferate_dr and severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685f2df1-c9d3-4b87-a83a-c551674e090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a4c722-6356-45d9-bc60-8f6008026b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Healthcare_projects\\diabetic_retinopathy\\colored_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26abf118-3484-4d46-be51-6a82d83866d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open each folder and perform data augmentation\n",
    "# 7220 images for each class\n",
    "\n",
    "def count_images_per_folder(base_dir):\n",
    "    folder_dict = {}\n",
    "    # count the number of images per folder and insert in dictionary\n",
    "    for folder in os.listdir(base_dir):\n",
    "        full_path = os.path.join(base_dir, folder)\n",
    "        if os.path.isdir(full_path):\n",
    "            count = sum(1 for file in os.listdir(full_path) if file.endswith('.png') and os.path.isfile(os.path.join(full_path, file)))\n",
    "            folder_dict[folder] = count\n",
    "    return folder_dict\n",
    "\n",
    "# target_count = max(class_dict.values()) * 8\n",
    "\n",
    "\n",
    "def additional_augmented_img(class_dict, target_count):\n",
    "    # count the number of additional images needed to augment each class \n",
    "    augment_needed = {}\n",
    "    for folder, count in class_dict.items():\n",
    "        augment_needed[folder] =  target_count - count\n",
    "    return augment_needed\n",
    "\n",
    "\n",
    "# Augmentation config\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "def data_augment_process(base_dir, augmented, class_dict, datagen, batch_size):\n",
    "    for folder in os.listdir(base_dir):\n",
    "        full_path = os.path.join(base_dir, folder)\n",
    "        if os.path.isdir(full_path):\n",
    "            existing_images = [f for f in os.listdir(full_path) if f.endswith('.png')]\n",
    "            \n",
    "            if folder in augmented and folder in class_dict:\n",
    "                current_count = class_dict[folder]\n",
    "                count_needed = augmented[folder]\n",
    "                img_index = current_count + 1\n",
    "                i = 0\n",
    "                while i < count_needed:\n",
    "                    for img_name in existing_images:\n",
    "                        img_path = os.path.join(full_path, img_name)\n",
    "                        img = load_img(img_path)\n",
    "                        x = img_to_array(img)\n",
    "                        x = x.reshape((1,) + x.shape)                    \n",
    "                        gen = datagen.flow(x, batch_size=batch_size)\n",
    "                        for batch in gen:\n",
    "                            for j in range(batch.shape[0]):\n",
    "                                if i >= count_needed:\n",
    "                                    break\n",
    "                                save_path = os.path.join(full_path, f\"{folder}_aug_{img_index}.png\")\n",
    "                                array_to_img(batch[j]).save(save_path)\n",
    "                                img_index += 1\n",
    "                                i += 1\n",
    "                            break  # 10 batch per image\n",
    "                        if i >= count_needed:\n",
    "                            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48be7ae1-c793-4822-8825-18bbb325283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = count_images_per_folder(base_dir)\n",
    "target_count = max(class_dict.values()) * 8\n",
    "augmented = additional_augmented_img(class_dict, target_count)\n",
    "data_augment_process(base_dir, augmented, class_dict, datagen, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1b9b7e3-9fec-45eb-b56b-69c0c2575894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # take 80% of the images and put in a train folder and 20% in the test folder in the main directory\n",
    "main_dir = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Healthcare_projects\\diabetic_retinopathy\"\n",
    "\n",
    "\n",
    "# Mapping of folder names to class labels\n",
    "data_dict = {\n",
    "    'No_DR': 0, \n",
    "    'Mild' : 1,\n",
    "    'Moderate': 2,\n",
    "    'Severe': 3,\n",
    "    'Proliferate_DR': 4}\n",
    "\n",
    "def pairing_data(base_dir, data_dict):\n",
    "    data = {}\n",
    "    for class_name, class_label in data_dict.items():\n",
    "        folder_path = os.path.join(base_dir, class_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                image_name = os.path.splitext(file)[0] # removes .png\n",
    "                image_name= str(image_name)\n",
    "                data[image_name] = class_label\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_dict_to_csv(data, output_path):\n",
    "    csv_path = os.path.join(output_path, \"image_labels.csv\")\n",
    "    df = pd.DataFrame(list(data.items()), columns=['image_name', 'label'])\n",
    "    df.to_csv(csv_path, index=False)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7dd37f57-168d-442e-98ae-386557033e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict_to_csv(pairing_data(base_dir, data_dict), main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d6b2bb0-32d1-4840-b1a8-44056b2b374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # image size\n",
    "# img_size = (224, 224)\n",
    "\n",
    "# X_train, y_train = [], []\n",
    "# X_test, y_test = [], []\n",
    "\n",
    "# for class_name, label in data_dict.items():\n",
    "#     folder_path = os.path.join(base_dir, class_name)\n",
    "#     image_files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "#     random.shuffle(image_files)  # shuffle for randomness\n",
    "    \n",
    "#     split_index = int(0.8 * len(image_files))\n",
    "    \n",
    "#     train_files = image_files[:split_index]\n",
    "#     test_files = image_files[split_index:]\n",
    "    \n",
    "#     # Load training images\n",
    "#     for file in train_files:\n",
    "#         img_path = os.path.join(folder_path, file)\n",
    "#         img = Image.open(img_path).resize(img_size)\n",
    "#         img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "#         X_train.append(img_array)\n",
    "#         y_train.append(label)\n",
    "    \n",
    "#     # Load testing images\n",
    "#     for file in test_files:\n",
    "#         img_path = os.path.join(folder_path, file)\n",
    "#         img = Image.open(img_path).resize(img_size)\n",
    "#         img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "#         X_test.append(img_array)\n",
    "#         y_test.append(label)\n",
    "\n",
    "# # Convert to NumPy arrays\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "# print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "# print(\"Testing set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434b1fc6-e110-4ffc-92c2-002058c5604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57760 images belonging to 5 classes.\n",
      "Found 14440 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # 80% train, 20% test\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=base_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # one-hot encoded labels\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory=base_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46dcf75-1179-4f2d-9ba9-64e04b3e2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proceed with the architecture\n",
    "# start with 3 layers and two maxpooling layers and check the performance\n",
    "\n",
    "model = Sequential([\n",
    "    keras.Input(shape=(224,224,3)), \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(5, activation='softmax')  # For 5 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bbb8e23-587c-4147-8bde-54a1a0323da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m11,075,712\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,605</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,605\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,605</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,605\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4599a49e-9691-4cfa-bf36-5c7fd2fc1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b38957-834b-4fd0-94be-ff47cf182f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2270s\u001b[0m 1s/step - accuracy: 0.4803 - loss: 1.2294 - val_accuracy: 0.6015 - val_loss: 0.9696\n",
      "Epoch 2/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2048s\u001b[0m 1s/step - accuracy: 0.6235 - loss: 0.9188 - val_accuracy: 0.7096 - val_loss: 0.7367\n",
      "Epoch 3/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1967s\u001b[0m 1s/step - accuracy: 0.7263 - loss: 0.7024 - val_accuracy: 0.8117 - val_loss: 0.5169\n",
      "Epoch 4/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1929s\u001b[0m 1s/step - accuracy: 0.8078 - loss: 0.5093 - val_accuracy: 0.8757 - val_loss: 0.3703\n",
      "Epoch 5/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1929s\u001b[0m 1s/step - accuracy: 0.8564 - loss: 0.3934 - val_accuracy: 0.8925 - val_loss: 0.3015\n",
      "Epoch 6/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1923s\u001b[0m 1s/step - accuracy: 0.8885 - loss: 0.3044 - val_accuracy: 0.9154 - val_loss: 0.2486\n",
      "Epoch 7/10\n",
      "\u001b[1m1805/1805\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1914s\u001b[0m 1s/step - accuracy: 0.9114 - loss: 0.2429 - val_accuracy: 0.9330 - val_loss: 0.2065\n",
      "Epoch 8/10\n",
      "\u001b[1m 323/1805\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:01\u001b[0m 932ms/step - accuracy: 0.9208 - loss: 0.2091"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=10, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f3b7b154-280b-4522-b97e-02a2beb82e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 346ms/step\n",
      "(14440, 5)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator, verbose=1)\n",
    "print(predictions.shape) \n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12ddb988-58eb-4319-a3f4-aeddb8c9f500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for key, val in data_dict.items():\n",
    "#     if val in predicted_classes: \n",
    "#         print(f\"{key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b384d079-6028-4250-90f6-02fbbaa05d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "# model.save(\"Diabetic_Retinopathy_CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f362453-9c38-4d0b-b6a1-cd837fb1acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model('Diabetic_Retinopathy_CNN.h5')  # or .keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6755304-4756-4c5e-a9f4-1f93b0fc6436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UltraBook 3.1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 375ms/step - accuracy: 0.9362 - loss: 0.1976\n",
      "Test Accuracy: 93.82%\n"
     ]
    }
   ],
   "source": [
    "# visualizations of th training data\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714b426-8ca3-44c0-b1ee-4e76a8b813fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
